---
area: "[[AI]]"
tags: [machine-learning, self-supervised-learning, representation-learning]
created: 2026-01-27
---
# 对比学习

## 定义

对比学习(Contrastive Learning)是一种自监督表示学习方法，通过比较样本之间的相似性来学习有意义的特征表示。其核心思想是：将相似样本（正样本对）的表示拉近，将不相似样本（负样本对）的表示推远。

## 要点

- **正样本对**：语义相似的样本对，如同一图像的不同增强版本、图像与其描述文本
- **负样本对**：语义不同的样本对，通常从同一批次中随机采样
- **InfoNCE 损失**：最常用的对比学习目标函数，基于噪声对比估计
- **温度参数**：控制相似度分布的平滑程度，通常设为 0.07 左右
- **大批次训练**：需要大量负样本以提供有效的对比信号

## 示例

典型的对比学习流程：

```python
# InfoNCE 损失计算
def info_nce_loss(query, positive_key, negative_keys, temperature=0.07):
    # 计算正样本相似度
    pos_sim = torch.sum(query * positive_key, dim=-1) / temperature

    # 计算所有负样本相似度
    neg_sim = torch.mm(query, negative_keys.T) / temperature

    # 对比损失
    logits = torch.cat([pos_sim.unsqueeze(1), neg_sim], dim=1)
    labels = torch.zeros(len(query), dtype=torch.long)
    loss = F.cross_entropy(logits, labels)
    return loss
```

## 相关概念

- [[多模态表示学习]] - 对比学习在多模态场景的应用
- [[CLIP模型]] - 使用对比学习的视觉-语言模型
- [[自监督学习]] - 对比学习的上层范式
- [[SimCLR]] - 视觉对比学习的经典方法
- [[InfoNCE损失]] - 对比学习的核心损失函数

## 参考资料

- [A Simple Framework for Contrastive Learning of Visual Representations (SimCLR)](https://arxiv.org/abs/2002.05709)
- [Momentum Contrast for Unsupervised Visual Representation Learning (MoCo)](https://arxiv.org/abs/1911.05722)
