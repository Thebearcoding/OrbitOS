---
area: "[[AI]]"
tags: [machine-learning, transfer-learning, classification]
created: 2026-01-27
---
# 零样本学习

## 定义

零样本学习(Zero-shot Learning)是指模型在推理时能够处理训练过程中从未见过的类别或任务的能力。模型通过学习类别的语义描述（如自然语言文本）来泛化到新类别，而无需针对这些类别的标注数据进行微调。

## 要点

- **语义迁移**：利用类别名称或描述的语义信息进行迁移
- **开放词汇**：不受预定义类别集合的限制
- **无需微调**：直接应用预训练模型到新任务
- **提示工程**：通过设计文本提示(prompt)来引导模型行为

## 示例

CLIP 的零样本分类能力：

```python
from transformers import CLIPProcessor, CLIPModel

model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# 定义新类别（训练时可能未见过）
new_categories = ["一只柯基犬", "一只布偶猫", "一只金毛犬", "一只暹罗猫"]

# 零样本分类
inputs = processor(
    text=new_categories,
    images=image,
    return_tensors="pt",
    padding=True
)

outputs = model(**inputs)
probs = outputs.logits_per_image.softmax(dim=1)

# 即使没有这些类别的训练数据，也能正确分类
for cat, prob in zip(new_categories, probs[0]):
    print(f"{cat}: {prob:.2%}")
```

**零样本 vs 少样本 vs 微调：**
- **零样本**：不需要目标类别的任何样本
- **少样本(Few-shot)**：需要少量目标类别的样本
- **微调(Fine-tuning)**：需要大量标注数据进行训练

## 相关概念

- [[CLIP模型]] - 具有强大零样本能力的视觉-语言模型
- [[对比学习]] - 使CLIP获得零样本能力的训练方法
- [[迁移学习]] - 零样本学习的上层范式
- [[提示学习]] - 通过设计提示增强零样本性能

## 参考资料

- [Language Models are Few-Shot Learners (GPT-3)](https://arxiv.org/abs/2005.14165)
- [Learning to Generalize from Zero-Shot Learning](https://arxiv.org/abs/1707.00600)
