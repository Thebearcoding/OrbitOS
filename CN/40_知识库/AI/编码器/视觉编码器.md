---
area: "[[AI]]"
tags: [neural-network, computer-vision, encoder]
created: 2026-01-27
---
# 视觉编码器

## 定义

视觉编码器(Vision Encoder)是将图像转换为高维特征向量的神经网络模块。它是计算机视觉和多模态学习系统的核心组件，负责从原始像素中提取语义信息。

## 要点

- **CNN 架构**：ResNet、EfficientNet 等卷积网络，擅长提取局部特征
- **Transformer 架构**：ViT (Vision Transformer)，将图像分割为 patch 序列处理
- **输出形式**：全局特征向量(CLS token)或特征图/序列
- **预训练**：通常在 ImageNet 或更大数据集上预训练

## 示例

常见的视觉编码器及其特点：

| 模型 | 架构 | 参数量 | 特点 |
|------|------|--------|------|
| ResNet-50 | CNN | 25M | 经典卷积网络 |
| ViT-B/32 | Transformer | 86M | patch size 32 |
| ViT-L/14 | Transformer | 307M | 更大模型 |
| ViT-G | Transformer | 1.8B | BLIP-2 使用 |

在 CLIP 中使用 ViT 提取图像特征：

```python
from transformers import CLIPVisionModel

vision_model = CLIPVisionModel.from_pretrained("openai/clip-vit-base-patch32")

# 输入: [batch, 3, 224, 224]
# 输出: last_hidden_state [batch, 50, 768], pooler_output [batch, 768]
outputs = vision_model(pixel_values=images)
image_features = outputs.pooler_output  # 全局特征
```

## 相关概念

- [[文本编码器]] - 文本模态的对应组件
- [[ViT]] - Vision Transformer 详解
- [[CLIP模型]] - 使用视觉编码器的多模态模型
- [[多模态表示学习]] - 视觉编码器的应用场景

## 参考资料

- [An Image is Worth 16x16 Words (ViT)](https://arxiv.org/abs/2010.11929)
- [Deep Residual Learning for Image Recognition (ResNet)](https://arxiv.org/abs/1512.03385)
